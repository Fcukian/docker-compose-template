# This is a sample docker-compose file for setting up a server with several addons and services you can use with Stremio.
#
# This template includes the following default services:
# - Traefik: Reverse proxy for routing traffic to the services
# - Flame/Honey: Start page for your server
# - Dash: Dashboard for monitoring server resources
# - Uptime Kuma: Status page for monitoring uptime
# - Watchtower: Auto-updating services
# - Dozzle: Web UI for viewing logs
#
# It has additional optional profiles for:
# - stremio: includes stremio addons and utilities
# - debrid_media_server: includes services for building a debrid media server
# - minecraft: includes services for running a Minecraft server with PaperMC
# - vaultwarden: a bitwarden compatible server written in Rust
# - zipline: a file upload server/url shortener/ShareX server. 
# - searxng: a self hosted search engine
# - plausible: self hosted, privacy friendly analytics
# - all: includes all profiles

# This file is only a template and it requires the .env file to be set up with the necessary environment variables. 
#
# Tips:
# 
# May need sudo perms to run docker compose commands, so run `sudo su` to switch to root user 
# or run each command with the `sudo` prefix.
#
# - Run `docker compose up -d` to start the services
# - Run `docker compose down` to stop the services
# - Run `docker compose logs -f` to view the logs of all services live (Ctrl+C to exit without stopping the services)
# - Run `docker compose logs -f <service-name>` to view the logs of a specific service live (Ctrl+C to exit without stopping the services)
# - Run `docker compose ps` to view the status of all services
# - Run `docker compose ps <service-name>` to view the status of a specific service
# 

services:
  traefik:
    image: traefik:v3
    container_name: traefik
    restart: unless-stopped
    ports:
      - 443:443
      - 80:80
    command:
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--entryPoints.web.address=:80"
      - "--entryPoints.websecure.address=:443"
      - "--entryPoints.web.http.redirections.entryPoint.to=websecure"
      - "--entryPoints.web.http.redirections.entryPoint.scheme=https"
      - "--certificatesresolvers.myresolver.acme.tlschallenge=true"
      - "--certificatesresolvers.myresolver.acme.email=${LETSENCRYPT_EMAIL?}"
      - "--certificatesresolvers.myresolver.acme.storage=/letsencrypt/acme.json"
      - "--log.level=INFO"
      - "--ping"
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - "./data/letsencrypt:/letsencrypt"
    healthcheck:
      test: ["CMD", "traefik", "healthcheck", "--ping"]
      interval: 10s
      timeout: 5s
      retries: 3
  # Start page for your server
  flame:
    image: pawelmalak/flame:multiarch
    container_name: flame
    restart: unless-stopped
    expose:
      - 5005
    environment:
      - PASSWORD=${FLAME_PASSWORD?}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.flame.rule=Host(`${FLAME_HOSTNAME?}`)"
      - "traefik.http.routers.flame.entrypoints=websecure"
      - "traefik.http.routers.flame.tls.certresolver=myresolver"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./data/flame:/app/data

  dash:
    image: mauricenino/dashdot:latest
    container_name: dash
    restart: unless-stopped
    expose:
      - 3001
    privileged: true
    environment:
      DASHDOT_PAGE_TITLE: ${DASHDOT_PAGE_TITLE:-dash.}
      DASHDOT_ALWAYS_SHOW_PERCENTAGES: true
      DASHDOT_SHOW_HOST: ${DASHDOT_SHOW_HOST:-true}
      DASHDOT_CUSTOM_HOST: ${DASHDOT_CUSTOM_HOST:-}
      DASHDOT_ACCEPT_OOKLA_EULA: true
      DASHDOT_NETWORK_SPEED_AS_BYTES: false
    volumes:
      - /:/mnt/host:ro
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.dash.rule=Host(`${DASHDOT_HOSTNAME?}`)"
      - "traefik.http.routers.dash.entrypoints=websecure"
      - "traefik.http.routers.dash.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Dash"
      - "flame.url=https://${DASHDOT_HOSTNAME?}"

  honey:
    image: ghcr.io/dani3l0/honey:latest
    container_name: honey
    restart: unless-stopped
    volumes:
      - ./data/honey:/app/dist/config
      - ./data/honey/img:/app/dist/img/custom
    expose:
      - 4173
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.honey.rule=Host(`${HONEY_HOSTNAME?}`)"
      - "traefik.http.routers.honey.entrypoints=websecure"
      - "traefik.http.routers.honey.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Honey"
      - "flame.url=https://${HONEY_HOSTNAME?}"

  # Status page for monitoring uptime
  uptime-kuma:
    image: louislam/uptime-kuma:latest
    container_name: kuma
    restart: unless-stopped
    expose:
      - 3001
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.uptime-kuma.rule=Host(`${UPTIME_KUMA_HOSTNAME?}`)"
      - "traefik.http.routers.uptime-kuma.entrypoints=websecure"
      - "traefik.http.routers.uptime-kuma.tls.certresolver=myresolver"
      - "traefik.http.routers.status-page.rule=Host(`${STATUS_PAGE_HOSTNAME?}`)"
      - "traefik.http.routers.status-page.entrypoints=websecure"
      - "traefik.http.routers.status-page.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Uptime Kuma"
      - "flame.url=https://${UPTIME_KUMA_HOSTNAME?}"
    volumes:
      - ./data/kuma:/app/data
      - /var/run/docker.sock:/var/run/docker.sock

  # Watchtower for auto-updating services
  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    restart: unless-stopped
    environment:
      TZ: ${TZ:-UTC}  
      WATCHTOWER_CLEANUP: "true"
      WATCHTOWER_SCHEDULE: ${AUTO_UPDATE_SCHEDULE:-0 0 6 * * *} # Run at 6am daily
      WATCHTOWER_NOTIFICATION_URL: ${AUTO_UPDATE_NOTIFICATION_URL:-}
      WATCHTOWER_NOTIFICATION_REPORT: "true"
      WATCHTOWER_NOTIFICATION_TEMPLATE: |
        {{- if .Report -}}
          {{- with .Report -}}
            {{- if ( or .Updated .Failed ) -}}
        {{len .Scanned}} Scanned, {{len .Updated}} Updated, {{len .Failed}} Failed
              {{- range .Updated}}
        - {{.Name}} ({{.ImageName}}): {{.CurrentImageID.ShortID}} updated to {{.LatestImageID.ShortID}}
              {{- end -}}
              {{- range .Skipped}}
        - {{.Name}} ({{.ImageName}}): {{.State}}: {{.Error}}
              {{- end -}}
              {{- range .Failed}}
        - {{.Name}} ({{.ImageName}}): {{.State}}: {{.Error}}
              {{- end -}}
            {{- end -}}
          {{- end -}}
        {{- else -}}
          {{range .Entries -}}{{.Message}}{{"\n"}}{{- end -}}
        {{- end -}}
    volumes:  
      - /var/run/docker.sock:/var/run/docker.sock

  # Web UI for viewing logs
  dozzle:
    image: amir20/dozzle:latest
    container_name: dozzle
    restart: unless-stopped
    expose: 
      - 8080
    environment:
      DOZZLE_ENABLE_ACTIONS: "true"
      DOZZLE_NO_ANALYTICS: "true"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.dozzle.rule=Host(`${DOZZLE_HOSTNAME?}`)"
      - "traefik.http.routers.dozzle.entrypoints=websecure"
      - "traefik.http.routers.dozzle.tls.certresolver=myresolver"
      - "traefik.http.routers.dozzle.middlewares=dozzle-auth"
      - "traefik.http.middlewares.dozzle-auth.basicauth.users=${DOZZLE_USERNAME?}:${DOZZLE_HASHED_PASSWORD?}"
      - "flame.type=app"
      - "flame.name=Dozzle"
      - "flame.url=https://${DOZZLE_HOSTNAME?}"
    healthcheck:
      test: ["CMD", "/dozzle", "healthcheck"]
      interval: 3s
      timeout: 30s
      retries: 5
      start_period: 30s
  # AIOStreams service
  aiostreams:
    image: viren070/aiostreams:latest
    container_name: aiostreams
    restart: unless-stopped
    expose:
      - 3000
    environment:
      - ADDON_PROXY=${AIOSTREAMS_ADDON_PROXY:-}
      - ADDON_PROXY_CONFIG=*:false,*.strem.fun:true   # only route requests to any strem.fun subdomain through the proxy
      - API_KEY=${AIOSTREAMS_API_KEY:-}
      - SECRET_KEY=${AIOSTREAMS_SECRET_KEY} # openssl rand -hex 16
      - DEFAULT_TIMEOUT=5000
      - TMDB_API_KEY=${TMDB_API_KEY} 
      - LOG_FORMAT=text
      - LOG_LEVEL=debug
      - LOG_SENSITIVE_INFO=true
      # <<<   The environment variables below are instructing our AIOStreams addon to use our other self hosted services, if you don't                  >>>
      # <<<   want to use them you can remove the environment variables from the .env file or set them to an empty string, or remove them from here     >>>
      - EASYNEWS_PLUS_URL=${AIOSTREAMS_EASYNEWS_PLUS_URL:-}
      - MEDIAFUSION_URL=${AIOSTREAMS_MEDIAFUSION_URL:-}
      - MEDIAFUSION_API_PASSWORD=${MEDIAFUSION_API_PASSWORD:-}
      - MEDIAFUSION_CONFIG_TIMEOUT=3000
      - COMET_URL=${AIOSTREAMS_COMET_URL:-}
      - FORCE_COMET_HOSTNAME=${COMET_HOSTNAME:-}
      - COMET_INDEXERS=${AIOSTREAMS_COMET_INDEXERS:-}
      - JACKETTIO_URL=${AIOSTREAMS_JACKETTIO_URL:-}
      - JACKETT_INDEXERS=${AIOSTREAMS_JACKETT_INDEXERS:-}
      - STREMIO_JACKETT_URL=${AIOSTREAMS_STREMIO_JACKETT_URL:-}
      - JACKETT_URL=${AIOSTREAMS_JACKETT_URL:-}
      - JACKETT_API_KEY=${JACKETT_API_KEY:-}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.aio.rule=Host(`${AIOSTREAMS_HOSTNAME?}`)"
      - "traefik.http.routers.aio.entrypoints=websecure"
      - "traefik.http.routers.aio.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=AIOStreams"
      - "flame.url=https://${AIOSTREAMS_HOSTNAME}"

    healthcheck:
      test: wget -qO- http://localhost:3000/health
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - stremio
      - all
  tmdb-addon:
    image: mrcanelas/tmdb-addon:latest
    container_name: tmdb-addon
    restart: unless-stopped
    expose:
      - 3232
    environment:
      - PORT=3232
      - TMDB_API=${TMDB_API_KEY?}  # https://www.themoviedb.org/settings/api
      - FANART_API=${FANART_API_KEY?}  # https://fanart.tv/get-an-api-key/
      - HOST_NAME=tmdb-${TMDB_ADDON_HOSTNAME?}
      - MONGODB_URI=mongodb://mongodb:27017/tmdb
      - META_TTL=604800  # 1 week
      - CATALOG_TTL=86400  # 1 day
      - NO_CACHE=false  # Enable cache, set to true to disable
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.tmdb.rule=Host(`${TMDB_ADDON_HOSTNAME?}`)"
      - "traefik.http.routers.tmdb.entrypoints=websecure"
      - "traefik.http.routers.tmdb.tls.certresolver=myresolver"
      - "traefik.http.services.tmdb.loadbalancer.server.port=3232"
      - "flame.type=app"
      - "flame.name=TMDB Addon"
      - "flame.url=https://${TMDB_ADDON_HOSTNAME?}"
    depends_on:
      mongodb:
        condition: service_healthy
    profiles:
      - stremio
      - all

  easynews-plus:
    image: ghcr.io/sleeyax/stremio-easynews-addon:latest
    container_name: easynews-plus
    restart: unless-stopped
    expose:
      - 1337
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.easynews.rule=Host(`${EASYNEWS_PLUS_HOSTNAME}`)"
      - "traefik.http.routers.easynews.entrypoints=websecure"
      - "traefik.http.routers.easynews.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Easynews+"
      - "flame.url=https://${EASYNEWS_PLUS_HOSTNAME}"
    profiles:
      - stremio
      - all

  comet:
    container_name: comet
    image: g0ldyy/comet:latest
    restart: unless-stopped
    expose:
      - 2020
    environment:
      - FASTAPI_HOST=0.0.0.0
      - FASTAPI_PORT=2020
      - FASTAPI_WORKERS=-1
      - DATABASE_TYPE=sqlite
      - DATABASE_URL=data/comet.db
      - DASHBOARD_ADMIN_PASSWORD=${COMET_ADMIN_PASSWORD}
      - DEBRID_PROXY_URL=http://warp:1080
      - INDEXER_MANAGER_TYPE=${COMET_INDEXER_TYPE:-prowlarr} # or jackett
      - INDEXER_MANAGER_URL=${COMET_INDEXER_URL:-http://prowlarr:9696}
      #http://prowlarr:9696 # or http://jackett:9117
      - INDEXER_MANAGER_API_KEY=${COMET_INDEXER_API_KEY:-${PROWLARR_API_KEY:-}} # or ${JACKETT_API_KEY:-}
      - INDEXER_MANAGER_INDEXERS=${COMET_INDEXERS:-[]} # comma separated list of indexer ids  # for jackett, get the names from https://github.com/Jackett/Jackett/tree/master/src/Jackett.Common/Definitions - for prowlarr you can write them like on the web dashboard
      - SCRAPE_ZILEAN=True
      - ZILEAN_URL=http://zilean:8181 # or https://zilean.elfhosted.com if not hosting zilean locally
      - ZILEAN_TAKE_FIRST=500
      - SCRAPE_TORRENTIO=True
      - SCRAPE_MEDIAFUSION=True
      - SCRAPE_COMET=True
      - MEDIAFUSION_URL=http://mediafusion:8000 # or https://mediafusion.elfhosted.com if not hosting mediafusion locally
      - STREMTHRU_URL=http://stremthru:8080 # or https://stremthru.13377001.xyz if not hosting stremthru locally
      - DOWNLOAD_TORRENT_FILES=False
      - REMOVE_ADULT_CONTENT=True
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.comet.rule=Host(`${COMET_HOSTNAME}`)"
      - "traefik.http.routers.comet.entrypoints=websecure"
      - "traefik.http.routers.comet.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Comet"
      - "flame.url=https://${COMET_HOSTNAME}"
    volumes:
      - ./data/comet:/app/data
    healthcheck: 
      test: wget -qO- http://127.0.0.1:2020/health
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - stremio
      - all

  
  # Mediaflow Proxy service
  mediaflow-proxy:
    image: mhdzumair/mediaflow-proxy
    container_name: mediaflow-proxy
    restart: unless-stopped
    expose:
      - 8888
    environment:
      API_PASSWORD: ${MEDIAFLOW_API_PASSWORD}
      PROXY_URL: http://warp:1080
      TRANSPORT_ROUTES: '{ "https://torrentio.strem.fun": { "proxy": true } }'
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.mediaflow.rule=Host(`${MEDIAFLOW_HOSTNAME}`)"
      - "traefik.http.routers.mediaflow.entrypoints=websecure"
      - "traefik.http.routers.mediaflow.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=MediaFlow Proxy"
      - "flame.url=https://${MEDIAFLOW_HOSTNAME}"
    healthcheck:
      test: python3 -c "import urllib.request; print(urllib.request.urlopen('http://127.0.0.1:8888/health').read().decode())"
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - stremio
      - all

  # MediaFusion
  mediafusion:
    image: mhdzumair/mediafusion:latest
    container_name: mediafusion
    restart: unless-stopped
    expose:
      - 8000
    env_file:
      - ./data/mediafusion/.env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      warp:
        condition: service_healthy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.mediafusion.rule=Host(`${MEDIAFUSION_HOSTNAME?}`)"
      - "traefik.http.routers.mediafusion.entrypoints=websecure"
      - "traefik.http.routers.mediafusion.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=MediaFusion"
      - "flame.url=https://${MEDIAFUSION_HOSTNAME?}"
    profiles:
      - stremio
      - all

  dramatiq-worker:
    image: mhdzumair/mediafusion:latest
    container_name: dramatiq-worker
    command: ["dramatiq", "api.task", "-p", "1", "-t", "4"]
    restart: unless-stopped
    env_file:
      - ./data/mediafusion/.env
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    profiles:
      - stremio
      - all

  browserless:
    image: ghcr.io/browserless/chromium
    container_name: browserless
    environment:
      - TIMEOUT=-1
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/json/version"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - stremio
      - all

  stremthru:
    image: muniftanjim/stremthru:latest
    container_name: stremthru
    restart: unless-stopped
    expose:
      - 8080
    environment:
      - STREMTHRU_HTTP_PROXY=http://warp:1080
      - STREMTHRU_TUNNEL=*:false,torrentio.strem.fun:true       # Only tunnel hostnames that block VPS access (e.g. Torrentio)
      - STREMTHRU_PROXY_AUTH=user1:pass1,user2:pass2
      - STREMTHRU_STORE_AUTH=*:realdebrid:abc...xyz             # Add apikey
      - STREMTHRU_STORE_TUNNEL=realdebrid:api                   # Only send RD API via tunnel, not all access (e.g playback)
      - STREMTHRU_STORE_CONTENT_PROXY=*:true,easydebrid:false,premiumize:false
      - STREMTHRU_PEER_URI=https://stremthru.13377001.xyz
      - STREMTHRU_DATABASE_URI=sqlite://./data/stremthru.db
      - STREMTHRU_REDIS_URI=redis://redis:6379  # redis://garnet:6379
    depends_on:
      warp:
        condition: service_healthy
    volumes:
      - ./data/stremthru:/app/data
      
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.stremthru.rule=Host(`${STREMTHRU_HOSTNAME?}`)"
      - "traefik.http.routers.stremthru.entrypoints=websecure"
      - "traefik.http.routers.stremthru.tls.certresolver=myresolver"
      - "traefik.http.services.stremthru.loadbalancer.server.port=8080"
      - "flame.type=app"
      - "flame.name=StremThru"
      - "flame.url=https://${STREMTHRU_HOSTNAME}"
    profiles:
      - stremio
      - all
  
  stremio-jackett:
    image: belmeg/stremio-addon-jackett
    container_name: stremio-jackett
    restart: unless-stopped
    expose:
      - 3000
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=${TZ:-UTC}  # Add timezone support
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.stremiojackett.rule=Host(`${STREMIO_JACKETT_HOSTNAME?}`)"
      - "traefik.http.routers.stremiojackett.entrypoints=websecure"
      - "traefik.http.routers.stremiojackett.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Stremio-Jackett"
      - "flame.url=https://${STREMIO_JACKETT_HOSTNAME}"
    profiles:
      - stremio
      - all
    
  jackettio:
    image: arvida42/jackettio:latest
    container_name: jackettio
    restart: unless-stopped
    expose:
      - 4000
    environment:
      - JACKETT_URL=http://jackett:9117
      - JACKETT_API_KEY=${JACKETT_API_KEY:-}
      - TMDB_ACCESS_TOKEN=${TMDB_ACCESS_TOKEN:-}
    volumes:
      - ./data/jackettio:/data
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.jackettio.rule=Host(`${JACKETTIO_HOSTNAME?}`)"
      - "traefik.http.routers.jackettio.entrypoints=websecure"
      - "traefik.http.routers.jackettio.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Jackettio"
      - "flame.url=https://${JACKETTIO_HOSTNAME}"
    profiles:
      - stremio
      - all
    
  zilean:
    image: ipromknight/zilean:latest
    restart: unless-stopped
    container_name: zilean
    tty: true
    environment:
      Zilean__Database__ConnectionString: Host=postgres;Database=zilean;Username=${POSTGRES_USER:-postgres};Password=${POSTGRES_PASSWORD:-postgres};Include Error Detail=true;Timeout=30;CommandTimeout=3600
      Zilean__Imdb__UseAllCores: true
      Zilean__Imdb__UseLucene: true
    healthcheck:
      test: curl --connect-timeout 10 --silent --show-error --fail http://localhost:8181/healthchecks/ping
      timeout: 60s
      interval: 30s
      retries: 10
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - zilean-tmp:/tmp
    profiles:
      - stremio
      - debrid_media_server
      - all

  prowlarr:
    image: ghcr.io/hotio/prowlarr:latest
    container_name: prowlarr
    environment:
      - PUID=1000
      - PGID=1000
      - UMASK=002
      - TZ=${TZ:-UTC}  # Add timezone support
    expose:
      - 9696
    volumes:
      - ./data/prowlarr:/config
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.prowlarr.rule=Host(`${PROWLARR_HOSTNAME?}`)"
      - "traefik.http.routers.prowlarr.entrypoints=websecure"
      - "traefik.http.routers.prowlarr.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Prowlarr"
      - "flame.url=https://${PROWLARR_HOSTNAME}"
    healthcheck:
      test: curl -f http://localhost:9696/ping
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    profiles:
      - stremio
      - all
      - debrid_media_server
      - indexers

  jackett:
    image: linuxserver/jackett:latest
    container_name: jackett
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=${TZ:-UTC}  # Add timezone support
    expose:
      - 9117
    volumes:
      - ./data/jackett:/config
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.jackett.rule=Host(`${JACKETT_HOSTNAME?}`)"
      - "traefik.http.routers.jackett.entrypoints=websecure"
      - "traefik.http.routers.jackett.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Jackett"
      - "flame.url=https://${JACKETT_HOSTNAME}"
    healthcheck:
      test: curl -f http://localhost:9117/health 
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    profiles:
      - stremio
      - all
      - indexers
  
  nzbhydra2:
    container_name: nzbhydra2
    image: ghcr.io/hotio/nzbhydra2:latest
    expose:
      - 5076
    environment:
      - PUID=1000
      - PGID=1000
      - UMASK=002
      - TZ=${TZ:-UTC} 
    volumes:
      - ./data/nzbhydra/config:/config
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.nzbhydra2.rule=Host(`${NZBHYDRA2_HOSTNAME?}`)"
      - "traefik.http.routers.nzbhydra2.entrypoints=websecure"
      - "traefik.http.routers.nzbhydra2.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=NZBHydra2"
      - "flame.url=https://${NZBHYDRA2_HOSTNAME}"
    profiles:
      - nzbhydra2
      - all
      - indexers

  flaresolverr:
    image: ghcr.io/flaresolverr/flaresolverr:latest
    container_name: flaresolverr
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8191/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - all
      - stremio
      - debrid_media_server
  
  byparr:
    image: ghcr.io/thephaseless/byparr
    container_name: byparr
    restart: unless-stopped
    environment:
      - LOG_LEVEL=INFO
    volumes:
      - ./data/byparr/screenshots:/app/screenshots 
    healthcheck:
      test: curl -f http://localhost:8191/health
      interval: 5m
      timeout: 10s
      retries: 3
      start_period: 10s
    profiles:
      - all
      - stremio
      - debrid_media_server

  stremio-server:
    image: stremio/server:latest
    container_name: stremio-server
    expose:
      - 11470
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.stremio-server.rule=Host(`${STREMIO_SERVER_HOSTNAME?}`)"
      - "traefik.http.routers.stremio-server.entrypoints=websecure"
      - "traefik.http.routers.stremio-server.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Stremio Server"
      - "flame.url=https://${STREMIO_SERVER_HOSTNAME}"
    profiles:
      - stremio
      - all

  # Warp for SOCKS5 proxy for AIOStreams, MediaFlow Proxy, and Prowlarr, MediaFusion
  warp:
    image: caomingjun/warp
    container_name: warp
    restart: unless-stopped
    device_cgroup_rules:
      - 'c 10:200 rwm'
    expose:
      - 1080
    environment:
      - WARP_SLEEP=5
    cap_add:
      - NET_ADMIN
    sysctls:
      - net.ipv6.conf.all.disable_ipv6=0
      - net.ipv4.conf.all.src_valid_mark=1
    volumes:
      - ./data/warp:/var/lib/cloudflare-warp
    healthcheck:
      test: curl -x "socks5h://127.0.0.1:1080" -fsSL "https://www.cloudflare.com/cdn-cgi/trace" | grep -qE "warp=(plus|on)" || exit 1
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 5s
    profiles:
      - stremio
      - all
      - debrid_media_server

  mongodb: 
    image: mongo:latest
    container_name: mongodb
    restart: unless-stopped
    volumes:
      - mongodb-data:/data/db
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongosh localhost:27017/test --quiet
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s
    profiles:
      - stremio
      - all

  postgres:
    image: postgres:17.2-alpine
    container_name: postgres
    restart: unless-stopped
    shm_size: 2G
    environment:
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      POSTGRES_DB: postgres
    volumes:
      - postgres-data:/var/lib/postgresql/data/pgdata
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 10s
      timeout: 5s
      retries: 5
    profiles:
      - debrid_media_server
      - stremio
      - all

  redis: 
    image: redis:latest
    container_name: redis
    restart: unless-stopped
    volumes:
      - redis-data:/data
    command: redis-server --appendonly yes --save 60 1
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    profiles:
      - stremio
      - all
  
  # garnet:
  #   image: 'ghcr.io/microsoft/garnet'
  #   command:
  #     - --lua
  #     - --lua-transaction-mode
  #   ulimits:
  #     memlock: -1
  #   container_name: garnet
  #   restart: unless-stopped
  #   # To avoid docker NAT, consider `host` mode.
  #   # https://docs.docker.com/compose/compose-file/compose-file-v3/#network_mode
  #   # network_mode: "host"
  #   volumes:
  #     - garnet-data:/data
  #   profiles:
  #     - stremio
  #     - all


  aiostremio:
    image: viren070/aiostremio:latest
    container_name: aiostremio
    restart: unless-stopped
    expose:
      - 8469
    volumes:
     - ./data/aiostremio:/app/data
    environment:
      ADMIN_USERNAME: ${AIOSTREMIO_ADMIN_USERNAME?}
      ADMIN_PASSWORD: ${AIOSTREMIO_ADMIN_PASSWORD?}
      MEDIAFLOW_API_PASSWORD: ${MEDIAFLOW_API_PASSWORD:-}
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: 
      DEBRID_API_KEY: ${DEBRID_API_KEY}
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.aiostremio.rule=Host(`${AIOSTREMIO_HOSTNAME?}`)"
      - "traefik.http.routers.aiostremio.entrypoints=websecure"
      - "traefik.http.routers.aiostremio.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=AIOStremio"
      - "flame.url=https://${AIOSTREMIO_HOSTNAME}"
    profiles:
      - stremio
      - all


  omg-tv-stremio-addon:
    build:
      context: https://github.com/mccoy88f/OMG-Premium-TV.git
      dockerfile: Dockerfile
    image: omg-tv-stremio-addon
    container_name: omg-tv-stremio-addon
    restart: unless-stopped
    expose:
      - 7860
    environment:
      - PORT=7860
      - HOST=0.0.0.0  
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.omg-tv-stremio-addon.rule=Host(`${OMG_TV_STREMIO_ADDON_HOSTNAME?}`)"
      - "traefik.http.routers.omg-tv-stremio-addon.entrypoints=websecure"
      - "traefik.http.routers.omg-tv-stremio-addon.tls.certresolver=myresolver"
      - "traefik.http.services.omg-tv-stremio-addon.loadbalancer.server.port=7860"
      - "flame.type=app"
      - "flame.name=OMG TV Stremio Addon"
      - "flame.url=https://${OMG_TV_STREMIO_ADDON_HOSTNAME}"
    profiles: 
      - stremio
      - all



  addon-manager:
    image: reddravenn/stremio-addon-manager:latest
    container_name: addon-manager
    restart: unless-stopped
    expose:
      - 80
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.addon-manager.rule=Host(`${ADDON_MANAGER_HOSTNAME?}`)"
      - "traefik.http.routers.addon-manager.entrypoints=websecure"
      - "traefik.http.routers.addon-manager.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Stremio Addon Manager"
      - "flame.url=https://${ADDON_MANAGER_HOSTNAME}"
    profiles:
      - stremio
      - all


  ravenn-catalogs:
    image: reddravenn/stremio-catalog-providers
    container_name: ravenn-catalogs
    expose:
      - 7000
    environment:
      PORT: 7000
      BASE_URL: https://${RAVENN_CATALOGS_HOSTNAME?}
      DB_USER: ${POSTGRES_USER:-postgres}
      DB_HOST: ravenn-postgres
      DB_NAME: stremio_catalog_db
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_PORT: 5432
      DB_MAX_CONNECTIONS: 20
      DB_IDLE_TIMEOUT: 30000
      DB_CONNECTION_TIMEOUT: 2000
      REDIS_HOST: ravenn-redis
      REDIS_PORT: 6379
      REDIS_PASSWORD:
      TRAKT_CLIENT_ID: ${TRAKT_CLIENT_ID?}
      TRAKT_CLIENT_SECRET: ${TRAKT_CLIENT_SECRET?}
      TRAKT_HISTORY_FETCH_INTERVAL: 1d
      CACHE_CATALOG_CONTENT_DURATION_DAYS: 1
      CACHE_POSTER_CONTENT_DURATION_DAYS: 7
      LOG_LEVEL: info
      LOG_INTERVAL_DELETION: 3d
      NODE_ENV: production
    depends_on:
      ravenn-postgres:
        condition: service_healthy
      ravenn-redis:
        condition: service_healthy
    volumes:
      - ./data/ravenn/catalogs/db:/usr/src/app/db
      - ./data/ravenn/catalogs/log:/usr/src/app/log
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.ravenn-catalogs.rule=Host(`${RAVENN_CATALOGS_HOSTNAME?}`)"
      - "traefik.http.routers.ravenn-catalogs.entrypoints=websecure"
      - "traefik.http.routers.ravenn-catalogs.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Stremio Catalogs"
      - "flame.url=https://${RAVENN_CATALOGS_HOSTNAME}"
    profiles:
      - stremio
      - all

  ravenn-trakt:
    image: reddravenn/stremio-trakt-addon
    container_name: ravenn-trakt
    expose:
      - 7000
    environment:
      PORT: 7000
      BASE_URL: https://${RAVENN_TRAKT_HOSTNAME?}
      DB_USER: ${POSTGRES_USER:-postgres}
      DB_HOST: ravenn-postgres
      DB_NAME: stremio_trakt_db
      DB_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
      DB_PORT: 5432
      DB_MAX_CONNECTIONS: 20
      DB_IDLE_TIMEOUT: 30000
      DB_CONNECTION_TIMEOUT: 2000
      REDIS_HOST: ravenn-redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: 
      TRAKT_CLIENT_ID: ${TRAKT_CLIENT_ID?}
      TRAKT_CLIENT_SECRET: ${TRAKT_CLIENT_SECRET?}
      TMDB_CACHE_DURATION: 1d
      TRAKT_CACHE_DURATION: 1d
      TRAKT_HISTORY_FETCH_INTERVAL: 1d
      LOG_LEVEL: info
      LOG_INTERVAL_DELETION: 3d
      NODE_ENV: production
    restart: unless-stopped
    depends_on:
      ravenn-postgres:
        condition: service_healthy
      ravenn-redis:
        condition: service_healthy
    volumes:
      - ./data/ravenn/trakt/cache:/usr/src/app/cache
      - ./data/ravenn/trakt/log:/usr/src/app/log
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.ravenn-trakt.rule=Host(`${RAVENN_TRAKT_HOSTNAME?}`)"
      - "traefik.http.routers.ravenn-trakt.entrypoints=websecure"
      - "traefik.http.routers.ravenn-trakt.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Stremio Trakt"
      - "flame.url=https://${RAVENN_TRAKT_HOSTNAME}"
    profiles:
      - stremio
      - all
  
  ravenn-postgres:
    container_name: ravenn-postgres
    image: postgres:16.4
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    volumes:
      - ravenn-postgres:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles: 
      - stremio
      - all

  ravenn-redis:
    container_name: ravenn-redis
    image: redis:6
    volumes:
      - ravenn-redis:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles: 
      - stremio
      - all


  # https://github.com/5rahim/seanime
  # App/Server for anime.
  seanime:
    image: umagistr/seanime
    container_name: seanime
    command: 
    volumes:
      - /mnt/user/anime:/anime
      - /mnt/user/downloads:/downloads
      - /mnt:/mnt
      - ./data/seanime:/root/.config/Seanime
    expose:
      - 43211
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.seanime.rule=Host(`${SEANIME_HOSTNAME?}`)"
      - "traefik.http.routers.seanime.entrypoints=websecure"
      - "traefik.http.routers.seanime.tls.certresolver=myresolver"
      - "traefik.http.routers.seanime.middlewares=seanime-auth"
      - "traefik.http.middlewares.seanime-auth.basicauth.users=${SEANIME_USERNAME?}:${SEANIME_HASHED_PASSWORD?}"
      - "flame.type=app"
      - "flame.name=Seanime"
      - "flame.url=https://${SEANIME_HOSTNAME}"
    healthcheck:
      test: wget -qO- http://localhost:43211/api/v1/status
      interval: 5m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - seanime
      - all
  
  searxng:
    container_name: searxng
    image: docker.io/searxng/searxng:latest
    restart: unless-stopped
    expose:
      - 8080
    volumes:
      - ./data/searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=https://${SEARXNG_HOSTNAME:-localhost}/
      - UWSGI_WORKERS=${SEARXNG_UWSGI_WORKERS:-4}
      - UWSGI_THREADS=${SEARXNG_UWSGI_THREADS:-4}
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.searxng.rule=Host(`${SEARXNG_HOSTNAME}`)"
      - "traefik.http.routers.searxng.entrypoints=websecure"
      - "traefik.http.routers.searxng.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=SearxNG"
      - "flame.url=https://${SEARXNG_HOSTNAME}"
    profiles:
      - searxng
      - all
  
  plausible_db:
    image: postgres:16-alpine
    restart: unless-stopped
    container_name: plausible-db
    volumes:
      - plausible-db:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      start_period: 1m
    profiles:
      - plausible
      - all

  plausible_events_db:
    image: clickhouse/clickhouse-server:24.3.3.102-alpine
    restart: unless-stopped
    container_name: plausible-events-db
    volumes:
      - plausible-event-db:/var/lib/clickhouse
      - plausible-event-logs:/var/log/clickhouse-server
      - ./data/plausible/clickhouse/logs.xml:/etc/clickhouse-server/config.d/logs.xml:ro
      - ./data/plausible/clickhouse/ipv4-only.xml:/etc/clickhouse-server/config.d/ipv4-only.xml:ro
      - ./data/plausible/clickhouse/low-resources.xml:/etc/clickhouse-server/config.d/low-resources.xml:ro
    ulimits:
      nofile: 
        soft: 262144
        hard: 262144
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 -O - http://127.0.0.1:8123/ping || exit 1"]
      start_period: 1m
    profiles:
      - plausible
      - all

  plausible:
    image: ghcr.io/plausible/community-edition:latest
    container_name: plausible
    restart: unless-stopped 
    command: sh -c "/entrypoint.sh db createdb && /entrypoint.sh db migrate && /entrypoint.sh run"
    depends_on:
      plausible_db:
        condition: service_healthy
      plausible_events_db:
        condition: service_healthy
    volumes:
      - plausible-data:/var/lib/plausible
    ulimits:
      nofile: 
        soft: 65535
        hard: 65535
    expose: 
      - 8000
    environment:
      TMPDIR: /var/lib/plausible/tmp
      BASE_URL: https://${PLAUSIBLE_HOSTNAME?}
      SECRET_KEY_BASE: ${PLAUSIBLE_SECRET_KEY_BASE?} 
      HTTP_PORT: 8000
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.plausible.rule=Host(`${PLAUSIBLE_HOSTNAME}`)"
      - "traefik.http.routers.plausible.entrypoints=websecure"
      - "traefik.http.routers.plausible.tls.certresolver=myresolver"
      - "traefik.http.services.plausible.loadbalancer.server.port=8000"
      - "flame.type=app"
      - "flame.name=Plausible"
      - "flame.url=https://${PLAUSIBLE_HOSTNAME}"
    profiles:
      - plausible
      - all
  
  zipline:
    image: ghcr.io/diced/zipline:v4
    container_name: zipline
    restart: unless-stopped
    expose:
      - 3000
    environment:
      - DATABASE_URL=postgres://${ZIPLINE_POSTGRES_USER:-zipline}:${ZIPLINE_POSTGRES_PASSWORD}@zipline-db:5432/${ZIPLINE_POSTGRES_DB:-zipline}
      - CORE_SECRET=${ZIPLINE_CORE_SECRET?}
    depends_on:
      zipline-db:
        condition: service_healthy
    volumes:
      - './data/zipline/uploads:/zipline/uploads'
      - './data/zipline/public:/zipline/public'
      - './data/zipline/themes:/zipline/themes'
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.zipline.rule=Host(`${ZIPLINE_HOSTNAME?}`)"
      - "traefik.http.routers.zipline.entrypoints=websecure"
      - "traefik.http.routers.zipline.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Zipline"
      - "flame.url=https://${ZIPLINE_HOSTNAME}"
    profiles:
      - zipline
      - all
    
  zipline-db:
    image: postgres:16
    restart: unless-stopped
    container_name: zipline-db
    volumes:
      - zipline-db:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${ZIPLINE_POSTGRES_USER:-zipline}
      POSTGRES_PASSWORD: ${ZIPLINE_POSTGRES_PASSWORD?}
      POSTGRES_DB: ${ZIPLINE_POSTGRES_DB:-zipline}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U zipline"]
      start_period: 1m
    profiles:
      - zipline
      - all

  # https://setupmc.com/java-server/
  # Use the above link to generate the service configuration for your Minecraft server.
  minecraft:
    image: itzg/minecraft-server:latest
    tty: true
    stdin_open: true
    container_name: minecraft
    ports:
      - "25565:25565"
    environment:
      EULA: "TRUE"
      TYPE: ${MINECRAFT_SERVER_TYPE:-PAPER}
      MEMORY: ${MINECRAFT_SERVER_MEMORY:-8G}
      MOTD: ${MINECRAFT_SERVER_MOTD:-"A Minecraft Server"}
      OVERRIDE_ICON: ${MINECRAFT_SERVER_OVERRIDE_ICON:-}
      ICON: ${MINECRAFT_SERVER_ICON:-}
      USE_AIKAR_FLAGS: "TRUE"
      TZ: ${TZ:-UTC}
      DIFFICULTY: "2"
      VIEW_DISTANCE: ${MINECRAFT_SERVER_VIEW_DISTANCE:-10}
      OPS: |-
        ${MINECRAFT_SERVER_OP:-}
      ENABLE_WHITE_LIST: ${MINECRAFT_SERVER_ENABLE_WHITE_LIST:-false}
      WHITELIST: ${MINECRAFT_SERVER_WHITELIST:-}
    volumes:
      - "./data/minecraft:/data"
    profiles:
      - minecraft
      - all
  
  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    restart: unless-stopped
    expose:
      - 80
    environment:
      DOMAIN: "https://${VAULTWARDEN_HOSTNAME?}"
      SIGNUPS_ALLOWED: ${VAULTWARDEN_SIGNUPS_ALLOWED:-true}
      ADMIN_TOKEN: ${VAULTWARDEN_ADMIN_TOKEN?}
    volumes:
      - ./data/vaultwarden:/data/
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.vaultwarden.rule=Host(`${VAULTWARDEN_HOSTNAME?}`)"
      - "traefik.http.routers.vaultwarden.entrypoints=websecure"
      - "traefik.http.routers.vaultwarden.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Vaultwarden"
      - "flame.url=https://${VAULTWARDEN_HOSTNAME?}"
    profiles:
      - vaultwarden
      - all

  

    
  # ================================================================================================== 
  #   DEBRID MEDIA SERVER
  # ==================================================================================================
  # This is incomplete and will be updated in the future with a proper guide. 
  # The below stack does mostly work, but there could be some permission issues which can be resolved with (not recommended):
  # - sudo chmod -R 777 /mnt/symlinks
  # You should only use the below as a reference. 
  blackhole:
    image: ghcr.io/westsurname/scripts/blackhole:latest
    container_name: blackhole
    user: "1000:1000"
    volumes:
      - ${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}:${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}:${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_SONARR_PATH}:/${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_SONARR_PATH}
      - ${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_RADARR_PATH}:/${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_RADARR_PATH}
      - ./data/blackhole/logs:/app/logs
      - /mnt:/mnt
    env_file:
      - ./data/blackhole/.env
    environment:
      - PUID=1000
      - PGID=1000
      - UMASK=002
      - SONARR_HOST=${SONARR_HOST}
      - SONARR_API_KEY=${SONARR_API_KEY}
      - RADARR_HOST=${RADARR_HOST}
      - RADARR_API_KEY=${RADARR_API_KEY}
      - BLACKHOLE_BASE_WATCH_PATH=${BLACKHOLE_BASE_WATCH_PATH}
    restart: unless-stopped
    depends_on:
      rclone:
        condition: service_started
      sonarr:
        condition: service_healthy
      radarr: 
        condition: service_healthy
    profiles:
      - debrid_media_server
      - all

  repair:
    image: ghcr.io/westsurname/scripts/scripts:latest
    container_name: repair
    command: python repair.py --no-confirm
    restart: unless-stopped
    env_file:
      - ./data/blackhole/.env
    environment:
      - SONARR_HOST=${SONARR_HOST}
      - SONARR_API_KEY=${SONARR_API_KEY}
      - RADARR_HOST=${RADARR_HOST}
      - RADARR_API_KEY=${RADARR_API_KEY}
    volumes: 
      - ${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}:${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}:${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${SONARR_ROOT_FOLDER}:${SONARR_ROOT_FOLDER}
      - ${RADARR_ROOT_FOLDER}:${RADARR_ROOT_FOLDER}
    depends_on:
      rclone:
        condition: service_started
      sonarr:
        condition: service_healthy
      radarr: 
        condition: service_healthy
    profiles:
      - debrid_media_server
      - all

  blackhole4k:
    image: ghcr.io/westsurname/scripts/blackhole:latest
    container_name: blackhole4k
    user: "1000:1000"
    volumes:
      - ${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}:${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}:${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_SONARR_PATH}4k:/${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_SONARR_PATH}
      - ${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_RADARR_PATH}4k:/${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_RADARR_PATH}
      - ./data/blackhole4k/logs:/app/logs
      - /mnt:/mnt
    env_file:
      - ./data/blackhole/.env
    environment:
      - BLACKHOLE_BASE_WATCH_PATH=${BLACKHOLE_BASE_WATCH_PATH}
      - PUID=1000
      - PGID=1000
      - UMASK=002
      - SONARR_HOST=${SONARR_HOST_4K}
      - SONARR_API_KEY=${SONARR_API_KEY_4K}
      - RADARR_HOST=${RADARR_HOST_4K}
      - RADARR_API_KEY=${RADARR_API_KEY_4K}
      - SONARR_ROOT_FOLDER=${SONARR_ROOT_FOLDER_4K}
      - RADARR_ROOT_FOLDER=${RADARR_ROOT_FOLDER_4K}
    restart: unless-stopped
    depends_on:
      rclone:
        condition: service_started
      sonarr4k:
        condition: service_healthy
      radarr4k:
        condition: service_healthy
    profiles:
      - debrid_media_server
      - all
    
  repair4k:
    image: ghcr.io/westsurname/scripts/scripts:latest
    container_name: repair4k
    command: python repair.py --no-confirm
    restart: unless-stopped
    env_file:
      - ./data/blackhole/.env
    environment:
      - SONARR_HOST=${SONARR_HOST_4K}
      - SONARR_API_KEY=${SONARR_API_KEY_4K}
      - RADARR_HOST=${RADARR_HOST_4K}
      - RADARR_API_KEY=${RADARR_API_KEY_4K}
    volumes: 
      - ${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}:${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}:${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${SONARR_ROOT_FOLDER_4K}:${SONARR_ROOT_FOLDER_4K}
      - ${RADARR_ROOT_FOLDER_4K}:${RADARR_ROOT_FOLDER_4K}
    depends_on:
      rclone:
        condition: service_started
      sonarr4k:
        condition: service_healthy
      radarr4k: 
        condition: service_healthy
    profiles:
      - debrid_media_server
      - all
    
  blackholeanime:
    image: ghcr.io/westsurname/scripts/blackhole:latest
    container_name: blackholeanime
    user: "1000:1000"
    volumes:
      - ${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}:${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}:${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_SONARR_PATH}anime:/${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_SONARR_PATH}
      - ${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_RADARR_PATH}anime:/${BLACKHOLE_BASE_WATCH_PATH}/${BLACKHOLE_RADARR_PATH}
      - ./data/blackholeanime/logs:/app/logs
      - /mnt:/mnt
    env_file:
      - ./data/blackhole/.env
    environment:
      - BLACKHOLE_BASE_WATCH_PATH=${BLACKHOLE_BASE_WATCH_PATH}
      - PUID=1000
      - PGID=1000
      - UMASK=002
      - SONARR_HOST=${SONARR_HOST_ANIME}
      - SONARR_API_KEY=${SONARR_API_KEY_ANIME}
      - RADARR_HOST=${RADARR_HOST_ANIME}
      - RADARR_API_KEY=${RADARR_API_KEY_ANIME}
      - SONARR_ROOT_FOLDER=${SONARR_ROOT_FOLDER_ANIME}
      - RADARR_ROOT_FOLDER=${RADARR_ROOT_FOLDER_ANIME}

    restart: unless-stopped
    depends_on:
      rclone:
        condition: service_started
      sonarranime:
        condition: service_healthy
      radarranime:
        condition: service_healthy
    profiles:
      - debrid_media_server
      - all
    
  repairanime:
    image: ghcr.io/westsurname/scripts/scripts:latest
    container_name: repairanime
    command: python repair.py --no-confirm
    restart: unless-stopped
    env_file:
      - ./data/blackhole/.env
    environment:
      - SONARR_HOST=${SONARR_HOST_ANIME}
      - SONARR_API_KEY=${SONARR_API_KEY_ANIME}
      - RADARR_HOST=${RADARR_HOST_ANIME}
      - RADARR_API_KEY=${RADARR_API_KEY_ANIME}
    volumes: 
      - ${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}:${REALDEBRID_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}:${TORBOX_MOUNT_TORRENTS_PATH:-/dev/null}
      - ${SONARR_ROOT_FOLDER_ANIME}:${SONARR_ROOT_FOLDER_ANIME}
      - ${RADARR_ROOT_FOLDER_ANIME}:${RADARR_ROOT_FOLDER_ANIME}
    depends_on:
      rclone:
        condition: service_started
      sonarranime:
        condition: service_healthy
      radarranime: 
        condition: service_healthy
    profiles:
      - debrid_media_server
      - all

  radarr:
    container_name: radarr
    environment:
      - PUID=1000
      - PGID=1000
    expose:
      - 7878
    hostname: radarr
    image: ghcr.io/hotio/radarr:release
    restart: unless-stopped
    volumes:
      - /mnt:/mnt
      - /opt/radarr:/config
      - /opt/scripts:/scripts
      - /usr/bin/rclone:/usr/bin/rclone
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.radarr.rule=Host(`${RADARR_HOSTNAME}`)"
      - "traefik.http.routers.radarr.entrypoints=websecure"
      - "traefik.http.routers.radarr.tls.certresolver=myresolver"
      - "traefik.http.services.radarr.loadbalancer.server.port=7878"
      - "flame.type=app"
      - "flame.name=Radarr"
      - "flame.url=https://${RADARR_HOSTNAME}"
    depends_on:
      - rclone
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:7878/ping | grep -q '\"status\": \"OK\"' || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - debrid_media_server
      - all


  radarr4k:
    container_name: radarr4k
    expose:
      - 7878
    environment:
      - PUID=1000
      - PGID=1000
    image: ghcr.io/hotio/radarr:release
    restart: unless-stopped
    volumes:
      - /mnt:/mnt
      - /opt/radarr4k:/config
      - /opt/scripts:/scripts
      - /usr/bin/rclone:/usr/bin/rclone
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.radarr4k.rule=Host(`${RADARR4K_HOSTNAME}`)"
      - "traefik.http.routers.radarr4k.entrypoints=websecure"
      - "traefik.http.routers.radarr4k.tls.certresolver=myresolver"
      - "traefik.http.services.radarr4k.loadbalancer.server.port=7878"
      - "flame.type=app"
      - "flame.name=Radarr4k"
      - "flame.url=https://${RADARR4K_HOSTNAME}"
    depends_on:
      - rclone
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:7878/ping | grep -q '\"status\": \"OK\"' || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - debrid_media_server
      - all

  radarranime:
    container_name: radarranime
    expose:
      - 7878
    image: ghcr.io/hotio/radarr:release
    environment:
      - PUID=1000
      - PGID=1000
    restart: unless-stopped
    volumes:
      - /mnt:/mnt
      - /opt/radarranime:/config
      - /opt/scripts:/scripts
      - /usr/bin/rclone:/usr/bin/rclone
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.radarranime.rule=Host(`${RADARRANIME_HOSTNAME}`)"
      - "traefik.http.routers.radarranime.entrypoints=websecure"
      - "traefik.http.routers.radarranime.tls.certresolver=myresolver"
      - "traefik.http.services.radarranime.loadbalancer.server.port=7878"
      - "flame.type=app"
      - "flame.name=RadarrAnime"
      - "flame.url=https://${RADARRANIME_HOSTNAME}"
    depends_on:
      - rclone
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:7878/ping | grep -q '\"status\": \"OK\"' || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - debrid_media_server
      - all
  
  sonarr:
    container_name: sonarr
    expose:
      - 8989
    image: ghcr.io/hotio/sonarr:release
    restart: unless-stopped
    environment:
      - PUID=1000
      - PGID=1000
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.sonarr.rule=Host(`${SONARR_HOSTNAME}`)"
      - "traefik.http.routers.sonarr.entrypoints=websecure"
      - "traefik.http.routers.sonarr.tls.certresolver=myresolver"
      - "traefik.http.services.sonarr.loadbalancer.server.port=8989"
      - "flame.type=app"
      - "flame.name=Sonarr"
      - "flame.url=https://${SONARR_HOSTNAME}"
    volumes:
      - /mnt:/mnt
      - /opt/sonarr:/config
      - /opt/scripts:/scripts
      - /usr/bin/rclone:/usr/bin/rclone
    depends_on:
      - rclone
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:8989/ping | grep -q '\"status\": \"OK\"' || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - debrid_media_server
      - all

  sonarr4k:
    container_name: sonarr4k
    environment:
      - PUID=1000
      - PGID=1000
    expose:
      - 8989
    image: ghcr.io/hotio/sonarr:release
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.sonarr4k.rule=Host(`${SONARR4K_HOSTNAME}`)"
      - "traefik.http.routers.sonarr4k.entrypoints=websecure"
      - "traefik.http.routers.sonarr4k.tls.certresolver=myresolver"
      - "traefik.http.services.sonarr4k.loadbalancer.server.port=8989"
      - "flame.type=app"
      - "flame.name=Sonarr4k"
      - "flame.url=https://${SONARR4K_HOSTNAME}"
    volumes:
      - /mnt:/mnt
      - /opt/sonarr4k:/config
      - /opt/scripts:/scripts
      - /usr/bin/rclone:/usr/bin/rclone
    depends_on:
      - rclone
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:8989/ping | grep -q '\"status\": \"OK\"' || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - debrid_media_server
      - all


  sonarranime:
    container_name: sonarranime
    expose:
      - 8989
    image: ghcr.io/hotio/sonarr:release
    environment:
      - PUID=1000
      - PGID=1000
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.sonarranime.rule=Host(`${SONARRANIME_HOSTNAME}`)"
      - "traefik.http.routers.sonarranime.entrypoints=websecure"
      - "traefik.http.routers.sonarranime.tls.certresolver=myresolver"
      - "traefik.http.services.sonarranime.loadbalancer.server.port=8989"
      - "flame.type=app"
      - "flame.name=SonarrAnime"
      - "flame.url=https://${SONARRANIME_HOSTNAME}"
    volumes:
      - /mnt:/mnt
      - /opt/sonarranime:/config
      - /opt/scripts:/scripts
      - /usr/bin/rclone:/usr/bin/rclone
    depends_on:
      - rclone
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:8989/ping | grep -q '\"status\": \"OK\"' || exit 1"]
      interval: 1m
      timeout: 10s
      retries: 5
      start_period: 10s
    profiles:
      - debrid_media_server
      - all


  recyclarr:
    image: ghcr.io/recyclarr/recyclarr:latest
    container_name: recyclarr
    user: "1000:1000"
    restart: unless-stopped
    environment:
      - TZ=${TZ:-UTC}
    volumes:
      - ./data/recyclarr:/config

  autosync:
    image: ghcr.io/pukabyte/autosync:latest
    container_name: autosync
    expose:
      - 3536
    volumes:
      - ./data/autosync/config.yaml:/app/config.yaml:ro
    restart: unless-stopped
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.autosync.rule=Host(`${AUTOSYNC_HOSTNAME}`)"
      - "traefik.http.routers.autosync.entrypoints=websecure"
      - "traefik.http.routers.autosync.tls.certresolver=myresolver"
      - "traefik.http.services.autosync.loadbalancer.server.port=3536"
      - "flame.type=app"
      - "flame.name=AutoSync"
      - "flame.url=https://${AUTOSYNC_HOSTNAME}"
    profiles:
      - debrid_media_server
      - all
  plex:
    image: plexinc/pms-docker:latest
    container_name: plex
    restart: unless-stopped
    ports:
      - 1900/udp
      - "32400:32400/tcp"
      - 32410/udp
      - 32412/udp
      - 32413/udp
      - 32414/udp
      - 32469/tcp
      - 8324/tcp
    expose:
      - 32400
    environment:
      - PLEX_UID=1000
      - PLEX_GID=1000
      - PLEX_CLAIM=${PLEX_CLAIM}
      - TZ=Europe/London
    volumes:
      - /dev/shm:/dev/shm
      - /mnt/local/transcodes/plex:/transcode
      - /mnt:/mnt
      - /opt/plex:/config
      - /opt/scripts:/scripts
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.plex.rule=Host(`${PLEX_HOSTNAME}`)"
      - "traefik.http.routers.plex.entrypoints=websecure"
      - "traefik.http.routers.plex.tls.certresolver=myresolver"
      - "traefik.http.services.plex.loadbalancer.server.port=32400"
      - "traefik.http.middlewares.plex-https-redirect.redirectscheme.scheme=https" 
      - "traefik.http.routers.plex.middlewares=plex-https-redirect"
      - "flame.type=app"
      - "flame.name=Plex"
      - "flame.url=https://${PLEX_HOSTNAME}"
    depends_on:
      - rclone
    profiles:
      - debrid_media_server
      - all

  jellyfin:
    image: lscr.io/linuxserver/jellyfin:latest
    restart: unless-stopped
    container_name: jellyfin
    expose:
      - 8096
    environment:
      - TZ=${TZ:-UTC}
    volumes:
      - ./data/jellyfin:/config
      - /mnt:/mnt
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.jellyfin.rule=Host(`${JELLYFIN_HOSTNAME}`)"
      - "traefik.http.routers.jellyfin.tls=true"
      - "traefik.http.services.jellyfin.loadbalancer.server.port=8096"
      - "traefik.http.routers.jellyfin.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Jellyfin"
      - "flame.url=https://${JELLYFIN_HOSTNAME}"
    depends_on:
      - rclone
    profiles:
      - debrid_media_server
      - all

  jellyseer:
    image: fallenbagel/jellyseerr:latest
    container_name: jellyseer
    restart: unless-stopped
    expose:
      - 5055
    environment:
      - TZ=${TZ:-UTC}
      - LOG_LEVEL=debug
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.jellyseer.rule=Host(`${JELLYSEER_HOSTNAME}`)"
      - "traefik.http.routers.jellyseer.entrypoints=websecure"
      - "traefik.http.routers.jellyseer.tls.certresolver=myresolver"
      - "flame.type=app"
      - "flame.name=Jellyseer"
      - "flame.url=https://${JELLYSEER_HOSTNAME}"
    volumes:
      - ./data/jellyseer:/app/config
    depends_on:
      - rclone
    profiles:
      - debrid_media_server
      - all
    
  zurg: 
    image: ghcr.io/debridmediamanager/zurg-testing:v0.9.3-final
    container_name: zurg
    restart: unless-stopped
    healthcheck:
      test: curl -f localhost:9999/dav/version.txt || exit 1
    ports:
      - 9999:9999
    volumes:
      - ./data/zurg/config.yml:/app/config.yml
      - ./data/zurg/data:/app/data
    profiles:
      - debrid_media_server
      - all

  rclone:
    image: rclone/rclone:latest
    container_name: rclone
    restart: unless-stopped
    environment:
      TZ: ${TZ:-UTC}
      PUID: 1000
      PGID: 1000
    volumes:
      - /mnt/remote/realdebrid:/data:rshared
      - ./data/zurg/rclone.conf:/config/rclone/rclone.conf
      - /mnt:/mnt
    cap_add:
      - SYS_ADMIN
    security_opt:
      - apparmor:unconfined
    devices:
      - /dev/fuse:/dev/fuse:rwm
    depends_on:
      zurg:
        condition: service_healthy
        restart: true
    command: "mount zurg: /data --allow-non-empty --allow-other --uid=1000 --gid=1000 --umask=002 --dir-cache-time 10s"
    profiles: 
      - debrid_media_server
      - all

volumes:
  zilean-tmp:
  redis-data:
  postgres-data:
  mongodb-data:
  ravenn-postgres:
  ravenn-redis:
  plausible-db:
  plausible-data:
  plausible-event-db:
  plausible-event-logs:
  garnet-data:
  zipline-db:



networks:
  default:
    name: ${DOCKER_NETWORK:-aio_default}
    external: ${DOCKER_NETWORK_EXTERNAL:-false}